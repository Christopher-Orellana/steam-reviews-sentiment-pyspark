{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3214428d-171c-49df-b880-32ca96702574",
   "metadata": {},
   "source": [
    "# Steam Review Dataset Feature Engineering and Modeling\n",
    "This notebook performs feature engineering on a cleaned dataset of Steam reviews using PySpark. It includes review text processing, timestamp decomposition, and the creation of cyclical and behavioral features to support sentiment classification tasks at scale using GCP Dataproc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5230d5e8-25d9-4128-a199-031eb37cee0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce07b7e5-a17e-47b7-a885-fb6f728acbd0",
   "metadata": {},
   "source": [
    "## 1. Imports and Loading/Inspection of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25c6cb7-c35a-466d-84f9-3b1f60c7f2ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124c1fee-8fa9-4ec8-811b-6f5d22a32698",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, isnan, isnull, when, count, udf, size, split, year, month, format_number, date_format, length, lit, from_unixtime, sin\n",
    "from pyspark.sql.types import IntegerType, DateType, StringType, StructType, DoubleType\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder, Normalizer, StandardScaler, HashingTF, IDF, Tokenizer, RegexTokenizer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression \n",
    "from pyspark.ml.regression import GeneralizedLinearRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16c5727-0193-45b2-8a24-321774992feb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.shuffle.partitions\", 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852a367b-04cc-422d-82aa-c4c2d8aff02b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up paths to file (Make sure to replace the bucket variable below with the path to your bucket)\n",
    "bucket = 'gs://whatever-your-bucket-name-is'\n",
    "landing_folder = f'{bucket}/landing/'\n",
    "cleaned_folder = f'{bucket}/cleaned/'\n",
    "trusted_folder = f'{bucket}/trusted/'\n",
    "models_folder = f'{bucket}/models/'\n",
    "cleaned_filename = f'{cleaned_folder}/cleaned_steam_reviews_data.parquet/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b572b869-2f88-47bb-9b4c-eef675554a4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#read in cleaned file\n",
    "sdf = spark.read.parquet(cleaned_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad579fe8-c540-419b-bd83-db941e8b47f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#set dynamic columns\n",
    "column_list = sdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8bb474-eac5-428b-8156-c792af60d9ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#check dataset column statistics\n",
    "sdf.summary().show(vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907356b6-7de0-4616-915d-7010b455c421",
   "metadata": {},
   "source": [
    "## 2. Timestamp Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d284f195-e0a1-451d-956b-976ba40a029c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create wordcount column for reviews\n",
    "sdf = sdf.withColumn('review_wordcount', size(split(col('clean_review'), ' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b62542-cfe8-4e5e-88ac-b8f403993b52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#filter out short reviews\n",
    "sdf = sdf.where(length(sdf.clean_review) > 10)\n",
    "\n",
    "#filter out reviews with less than 5 words\n",
    "sdf = sdf.where(sdf.review_wordcount > 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b3f188-0fb7-493d-8a08-0521355056a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#change column name for clarity\n",
    "sdf = sdf.withColumnRenamed('timestamp_created', 'unix_timestamp_created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0133bee2-35e2-435f-8f2d-9d0571e83ae6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#transform unix timestamp into spark readable time\n",
    "sdf = sdf.withColumn('fe_timestamp_created', from_unixtime('unix_timestamp_created'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e336a66-d949-474e-b178-02d5f9a38fee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Double check schema\n",
    "sdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb3c8cd-b4e4-4c7d-87a8-3d7a97fbb29e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import year, month, dayofmonth, dayofweek, hour, minute, weekofyear\n",
    "# Create dictionary to apply functions to create features from timestamp\n",
    "timestamp_feature = {\n",
    "    'month': month,\n",
    "    'weekday': dayofweek,\n",
    "    'hour': hour,\n",
    "}\n",
    "\n",
    "for name, function in timestamp_feature.items():\n",
    "    sdf = sdf.withColumn(name, function('fe_timestamp_created'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3820a21b-e318-4393-9a72-eb023aa9ef89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make date features cyclical to help model understand time related patterns\n",
    "sdf = sdf.withColumn('hour_sin', sin(2 * 3.1416 * col('hour') / 24))\n",
    "sdf = sdf.withColumn('month_sin', sin(2 * 3.1416 * col('month') / 24))\n",
    "sdf = sdf.withColumn('weekday_sin', sin(2 * 3.1416 * col('weekday') / 24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e96e0b-b726-4311-8d57-60d7635dfb52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sdf.show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f19430-9064-431a-8ea1-18538cea63f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Rename column for clarity\n",
    "sdf = sdf.withColumnRenamed('author_last_played', 'author_last_played_unix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f17423-2e27-4e91-a182-f689f0e3b6cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Transfrom column from unix time stamp to year-month-day for feature engineering\n",
    "sdf = sdf.withColumn('author_last_played_fe', from_unixtime('author_last_played_unix'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48b2491-09d6-4953-889c-d6481466129c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sdf.show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca5dea8-b52a-4a26-90ad-82c6512908b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#dictionary to apply functions to create features from author_last_played = alp features\n",
    "alp_timestamp_feature = {\n",
    "    'alp_month': month,\n",
    "    'alp_weekday': dayofweek,\n",
    "    'alp_hour': hour,\n",
    "}\n",
    "\n",
    "for alpname, alpfunction in alp_timestamp_feature.items():\n",
    "    sdf = sdf.withColumn(alpname, alpfunction('author_last_played_fe'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92385690-901f-4dc0-9534-4e5201631d11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#make date features cyclical for model\n",
    "sdf = sdf.withColumn('alp_hour_sin', sin(2 * 3.1416 * col('alp_hour') / 24))\n",
    "sdf = sdf.withColumn('alp_month_sin', sin(2 * 3.1416 * col('alp_month') / 24))\n",
    "sdf = sdf.withColumn('alp_weekday_sin', sin(2 * 3.1416 * col('alp_weekday') / 24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f24e05-98cb-4e65-b9be-989597e3e390",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sdf.show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8e2846-ac06-4815-b8a9-f8015ae67147",
   "metadata": {},
   "source": [
    "## 3. Text Feature Engineering & Sentiment Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bef5c77-3f6e-4079-ae65-09d89e83313c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#columns we are excluding from double cast\n",
    "double_exclusion_columns = ['review', 'game', 'clean_review', 'language', 'author_last_played_fe', 'fe_timestamp_created'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c07ae3c-5b87-4197-82d5-35bbdb1eafcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#select all columns we are casting double to\n",
    "columns_to_double = [c for c in sdf.columns if c not in double_exclusion_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858b0cc7-b931-456a-b421-3cbf40fb0d6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for column in columns_to_double:\n",
    "    sdf = sdf.withColumn(column, col(column).cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da78c892-1b4d-48fd-ad6f-212cb264a014",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#check if double broadcast worked \n",
    "sdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c798fb-57fb-4497-99a3-3f022977fff4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#set up tokenizer TF and IDF\n",
    "tokenizer = RegexTokenizer(inputCol='clean_review', outputCol='clean_review_words', pattern='\\\\w+', gaps=False)\n",
    "sdf = tokenizer.transform(sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c617c9f-54fa-48e9-a934-9555aa1ca056",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#running hash function over tokens\n",
    "sdf = sdf.drop('clean_review_tf')\n",
    "hashtf = HashingTF(numFeatures=1024, inputCol='clean_review_words', outputCol='clean_review_tf')\n",
    "\n",
    "sdf = hashtf.transform(sdf)\n",
    "\n",
    "print(\"Hashed sdf record count\", sdf.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4a4cb1-2ba9-4d43-b3a5-05ab24adab1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop just to make sure IDF can output col\n",
    "sdf = sdf.drop('clean_review_features')\n",
    "#create inverse document frequency vectors\n",
    "idf = IDF(inputCol='clean_review_tf', outputCol='clean_review_features', minDocFreq=100)\n",
    "sdf = idf.fit(sdf).transform(sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec84df6-9bb6-4c99-8464-ec2f2c526a0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display Clean Review Feature\n",
    "sdf.select('clean_review_features').show(2, truncate=False, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc61bfc-1487-44e9-b9b6-87938b40f9ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#use textblob to get sentiment analysis of review column\n",
    "from textblob import TextBlob\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.functions import col, isnan, when, count, udf\n",
    "\n",
    "# Create a function to perform sentiment analysis on text\n",
    "def sentiment_analysis(some_text):\n",
    "    sentiment = TextBlob(some_text).sentiment.polarity\n",
    "    return sentiment\n",
    "\n",
    "#turn function into UDF\n",
    "sentiment_analysis_udf = udf(sentiment_analysis, DoubleType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7e7c81-67c6-4d12-9d1d-23d8eb97ce7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#using sentiment_analysis_udf to create clean_review_sentiment column\n",
    "sdf = sdf.withColumn('clean_review_sentiment', sentiment_analysis_udf(sdf['clean_review']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e28add2-1ccd-47d6-bcdb-0946acdc9e92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display cleaned review and Sentiment score from TextBlob\n",
    "sdf.select('clean_review', 'clean_review_sentiment').show(2, truncate=False, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f21b45-0c33-4f69-b6f5-646091de7a3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sdf.show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21faf15-57ae-473c-b555-53b0ce5d607c",
   "metadata": {},
   "source": [
    "## 4. Categorical Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb39b76b-a2ba-4e4d-9e3e-1de68d4535cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pick top 200 games to encode categorically\n",
    "top_games = sdf.groupby('game').count().orderBy('count', ascending=False).limit(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ecef14-1b47-47d1-a916-3bdb4b0010a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "top_games.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a9f6fa-9b15-4317-a1cb-7686ec9eac2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#get list of games from top_games\n",
    "top_game_list = [row['game'] for row in top_games.collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8926490d-7a60-49de-ae18-797a55d27dc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#limit games to top 200 and refer to games after top 200 as other\n",
    "sdf = sdf.withColumn('game', when(col('game').isin(top_game_list), col('game')).otherwise('other'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bfbef8-b5ad-4a5c-bdd0-ab65bd2a7caf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#rename label for clarity\n",
    "sdf = sdf.withColumnRenamed('voted_up', 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0cd120-8d0b-4bef-b0b5-40763bb38539",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create age of review features\n",
    "from pyspark.sql.functions import abs, floor\n",
    "sdf = sdf.withColumn('age_of_review_unix', abs(col('unix_timestamp_created')) - abs(col('author_last_played_unix')))\n",
    "sdf = sdf.withColumn('age_of_review_fe', from_unixtime('age_of_review_unix'))\n",
    "\n",
    "#compute days that have passed between review time an d last played time\n",
    "sdf = sdf.withColumn('age_of_review_days', floor(abs(col('age_of_review_unix')) / 86400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac494f20-765a-460b-bab9-c1874c74c154",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sdf.show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7af61a-b4b4-4d4d-ae8f-1b969b2d742c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Bucketizer\n",
    "#match index for seasonal month to use bucketizer\n",
    "sdf = sdf.withColumn('shifted_month', when(col('month') == 12, 0).otherwise(col('month')))\n",
    "\n",
    "#seasonal splits foir bucketizer\n",
    "season_splits = [0, 3, 6, 9, 12]\n",
    "\n",
    "# Engineer seasonal bucket feature\n",
    "bucketizer = Bucketizer(splits=season_splits, inputCol='shifted_month', outputCol='season_bucket')\n",
    "sdf = bucketizer.setHandleInvalid('keep').transform(sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee2cae1-1f6b-4630-be81-4b85e6e9a316",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check Seasonal bucket feature counts\n",
    "sdf.groupBy('season_bucket').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f4addc-0a5b-400f-9b0b-d0285a478c81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make sure binary column doesnt have any non binary values\n",
    "sdf = sdf.filter((col('steam_purchase') <= 1) & (col('steam_purchase') >= 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c83de7-c89d-4411-b765-e79386f767c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sdf.groupBy('steam_purchase').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa48518-8144-4fe7-ad0c-9105cf13de3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make sure binary column doesnt have any non binary values\n",
    "sdf = sdf.filter((col('received_for_free') <= 1) & (col('received_for_free') >= 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478d4917-0da4-47cd-9490-c1e2400e03a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sdf.groupBy('received_for_free').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec41e7ef-aef2-4b4e-9552-eeccdd87a46d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make sure binary column doesnt have any non binary values\n",
    "sdf = sdf.filter((col('written_during_early_access') <= 1) & (col('written_during_early_access') >= 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0840a3-4b3f-4bba-be28-bb2360d99e45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sdf.groupBy('written_during_early_access').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2461ed50-0778-4724-b987-a0c328e55ee6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check age_of_review_days feature \n",
    "sdf.select('age_of_review_days').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8181a0-1c99-41c2-8212-b1fb495bb17b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sdf.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e284b30-f9eb-4bb2-bc08-d496d9e2671f",
   "metadata": {},
   "source": [
    "## 5. Assembling ML Pipeline and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bdfdf9-9fc4-442a-92c8-11e4bd5f4348",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#list continous data columns\n",
    "continous_columns_list = [\n",
    " 'author_num_games_owned',\n",
    " 'author_num_reviews',\n",
    " 'author_playtime_forever',\n",
    " 'author_playtime_last_two_weeks',\n",
    " 'author_playtime_at_review',\n",
    " 'steam_purchase',\n",
    " 'received_for_free',\n",
    " 'written_during_early_access',\n",
    " 'clean_review_length',\n",
    " 'review_wordcount',\n",
    " 'clean_review_sentiment',\n",
    " 'hour_sin',\n",
    " 'month_sin',\n",
    " 'weekday_sin',\n",
    " 'alp_hour_sin',\n",
    " 'alp_month_sin',\n",
    " 'alp_weekday_sin',\n",
    " 'age_of_review_days'\n",
    "]\n",
    "#index top 1000 games ML PIPELINE1\n",
    "game_indexer = StringIndexer(inputCol='game', outputCol='game_index')\n",
    "\n",
    "#OHE 1000 top games encoded for indexes ML PIPELINE 2\n",
    "encoder = OneHotEncoder(inputCols=['game_index', 'season_bucket'], outputCols=['game_ohe', 'season_ohe'], dropLast=True)\n",
    "\n",
    "#assemble continuous columns into vector ML PIPELINE 3\n",
    "continuous_assembler = VectorAssembler(inputCols=continous_columns_list, outputCol='continousVector')\n",
    "\n",
    "#scale the continous columns ML PIPELINE 4\n",
    "scaler = StandardScaler(inputCol='continousVector', outputCol='continuous_scaled')\n",
    "\n",
    "#assemble all of the vectors together into one large vector ML PIPELINE 5\n",
    "final_assembler = VectorAssembler(inputCols=['continuous_scaled', 'game_ohe', 'clean_review_features', 'season_ohe'], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5834a109-5271-4acb-92e7-8587c5135064",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create estimator\n",
    "lr = LogisticRegression(featuresCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecd17e9-c87c-4982-875d-fa9b6ed0eec8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#assemble pipeline\n",
    "machine_learning_pipeline = Pipeline(stages=[game_indexer, encoder, continuous_assembler, scaler, final_assembler, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72585fb8-f09a-4562-a9b1-f597fcc5eca2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#split into training and test\n",
    "trainingData, testData = sdf.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830ef1eb-1407-471a-8d2f-491c6ab8b52a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create evaluator\n",
    "evaluator = BinaryClassificationEvaluator(metricName='areaUnderROC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7e027d-c39b-43b7-a0ca-e7ee2cdb2b10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create a grid to hold hyperparameters\n",
    "grid = ParamGridBuilder()\n",
    "grid = grid.addGrid(lr.regParam,  [0.0, 0.5, 1.0])\n",
    "grid = grid.addGrid(lr.elasticNetParam, [0, 1])\n",
    "\n",
    "#build parameter grid\n",
    "grid = grid.build()\n",
    "\n",
    "#show # of models tested\n",
    "print('Number of models to be tested: ', len(grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a921fd-f8aa-45d0-bc16-ea327b3445d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create cross validator\n",
    "cv = CrossValidator(estimator=machine_learning_pipeline,\n",
    "                    estimatorParamMaps=grid,\n",
    "                    evaluator=evaluator,\n",
    "                    numFolds=3,\n",
    "                    parallelism=2\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50adee14-417f-4f9b-97da-45d2dac38c1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#use CV to fit data\n",
    "all_models = cv.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de8a145-764c-4fe0-814d-795283051574",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#use bestModel to run model on test data\n",
    "best_model = all_models.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0973ef-fca2-4464-ab33-c9e2fc3264d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the model to the models folder\n",
    "model_path =  f'{models_folder}/steam_reviews_logistic_regression_model_2'\n",
    "best_model.write().overwrite().save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e39eaf-b080-4d3a-8f5a-a9df7d8cc6b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#show avg metric on all the model runs\n",
    "print(f'Average metric: {all_models.avgMetrics}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dad5ac2-25a5-4e04-980a-59af18b34899",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#use the BestModel to run the model on the testData\n",
    "test_results = best_model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90199131-2430-42bc-9ad0-c96e8478a0d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#evaluate the predictions\n",
    "print(evaluator.evaluate(test_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37cc5de-a135-44af-89f7-a5706bd43731",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#show label and prediction\n",
    "test_results.select(['label', 'prediction']).show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5365881-caa2-45db-826f-005d0e9602ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create confusion matrix\n",
    "cm = test_results.groupby('label').pivot('prediction').count().fillna(0).sort('label', ascending=True).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d761e12-790c-49cf-b09f-cc4541cf43e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#function to calculate recall and precision\n",
    "def calculate_recall_precision(cm):\n",
    "    tn = cm[0][1]\n",
    "    fp = cm[0][2]\n",
    "    fn = cm[1][1]\n",
    "    tp = cm[1][2]\n",
    "    precision = tp / (tp +fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    f1_score = 2 * ((precision * recall) / (precision + recall))\n",
    "    return accuracy, precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7aa13af-a1c9-4a7b-b81a-0c54ae22a4b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assign evaluation metrics\n",
    "accuracy, precision, recall, f1_score = calculate_recall_precision(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6abf8e-e1f4-4d24-9aee-41629e7dc717",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(accuracy, precision, recall, f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4308a3-2394-4b4b-a47f-76c7023e42ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30895f8a-9d38-43e2-9005-a28894a28ee8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create Confusion matrix\n",
    "print(\"label,0.0,1.0\\n\", cm[0][0],\",\",cm[0][1],\",\",cm[0][2], \"\\n\", cm[1][0],\",\",cm[1][1],\",\",cm[1][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37433b6-0942-417b-aa3d-1f5aee76762c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Check stages in pipeline\n",
    "for i, stage in enumerate(best_model.stages):\n",
    "    print(f\"Stage {i}: {type(stage)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16edcce8-6582-4483-af93-6f00e521f51c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#look at parameters for the best model from grid\n",
    "paramap = best_model.stages[-1].extractParamMap()\n",
    "\n",
    "for p, v in paramap.items():\n",
    "    print(p, v)\n",
    "    \n",
    "#grab model stage\n",
    "mymodel = best_model.stages[-1]\n",
    "\n",
    "# Plot ROC curve for model evaluation\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(mymodel.summary.roc.select('FPR').collect(),\n",
    "         mymodel.summary.roc.select('TPR').collect())\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.savefig('roc1.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b4a7e6-8f3a-4c29-b358-c6320decbc50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "hyperparams = cv.getEstimatorParamMaps()[np.argmax(all_models.avgMetrics)]\n",
    "#print out hyperparams for best model\n",
    "for i in range(len(hyperparams.items())):\n",
    "    print([x for x in hyperparams.items()][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f571e941-c381-40e0-b534-6a49734535bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#extract the coefficients on each of the variables\n",
    "coeff = mymodel.coefficients.toArray().tolist()\n",
    "\n",
    "#extract original column names from features\n",
    "var_index = dict()\n",
    "for variable_type in ['numeric', 'binary']:\n",
    "    for variable in test_results.schema['features'].metadata['ml_attr']['attrs'][variable_type]:\n",
    "        print(f'Found variable: {variable}' )\n",
    "        idx = variable['idx']\n",
    "        name = variable['name']\n",
    "        var_index[idx] = name\n",
    "        \n",
    "#print out associated coefficients\n",
    "for i in range(len(var_index)):\n",
    "    print(f'Coefficient {i} {var_index[i]} {coeff[i]}')\n",
    "    \n",
    "import pandas as pd\n",
    "\n",
    "coef_df = pd.DataFrame({\n",
    "    'feature': [var_index[i] for i in range(len(var_index))],\n",
    "    'coefficient': coeff\n",
    "})\n",
    "\n",
    "#Find top 5 most influential features by absolute value for plotting\n",
    "top5 = coef_df.reindex(coef_df.coefficient.abs().sort_values(ascending=False).index).head(5)\n",
    "\n",
    "print(\"\\nTop 5 Most Influential Features:\")\n",
    "for i, row in top5.iterrows():\n",
    "    print(f\"{row['feature']}: {row['coefficient']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4e01f6-cfe1-48cf-84c8-15585c415bba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot sentiment score distributiopn by label class to see if Sentiment score helps Model discern\n",
    "sample = sdf.select(\"clean_review_sentiment\", \"label\").sample(False, 0.01).toPandas()\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.histplot(data=sample, x=\"clean_review_sentiment\", hue=\"label\", bins=50, stat=\"density\", common_norm=False)\n",
    "plt.title(\"Review Sentiment Score Distribution by Class\")\n",
    "plt.xlabel(\"Sentiment Score\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4277cad1-a567-4cfc-b30e-059ec40753bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot top 5 influential features from model\n",
    "top5 = coef_df.reindex(coef_df.coefficient.abs().sort_values(ascending=False).index).head(5)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.barplot(data=top5, x=\"coefficient\", y=\"feature\", orient=\"h\")\n",
    "plt.title(\"Top 5 Most Influential Features\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e5ce35-47ac-44c0-ae3c-3a9bb1f8f867",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract precision-recall points from the logistic regression summary\n",
    "pr_df = mymodel.summary.pr.toPandas()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(pr_df['recall'], pr_df['precision'], marker='o')\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
